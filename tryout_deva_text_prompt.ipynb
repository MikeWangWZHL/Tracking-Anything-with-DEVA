{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://colab.research.google.com/drive/1OsyNVoV_7ETD1zIE8UWxL3NXxu12m_YZ?usp=sharing#scrollTo=odl3HAdWc5Gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda.is_available(): True\n",
      "Number of available GPUs: 1\n",
      "torch.cuda.current_device():  0\n"
     ]
    }
   ],
   "source": [
    "# this block should be run in the beginning of the notebook\n",
    "\n",
    "import os, sys\n",
    "# sys.path.append(\"/data/wangz3/projects/ecole-video-action/third_party/Tracking-Anything-with-DEVA\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(\"cuda.is_available():\", cuda_available)\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(f\"Number of available GPUs: {num_gpus}\")\n",
    "print(f\"torch.cuda.current_device(): \", torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/wangz3/miniconda3/envs/ecole-video/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    import groundingdino\n",
    "    from groundingdino.util.inference import Model as GroundingDINOModel\n",
    "except ImportError:\n",
    "    import os, sys\n",
    "    sys.path.append(\"/data/wangz3/projects/ecole-video-action/third_party/Grounded-Segment-Anything\")\n",
    "    import GroundingDINO\n",
    "    from GroundingDINO.groundingdino.util.inference import Model as GroundingDINOModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cfg:\n",
      "{'DINO_NMS_THRESHOLD': 0.8,\n",
      " 'DINO_THRESHOLD': 0.35,\n",
      " 'GROUNDING_DINO_CHECKPOINT_PATH': './saves/groundingdino_swint_ogc.pth',\n",
      " 'GROUNDING_DINO_CONFIG_PATH': './saves/GroundingDINO_SwinT_OGC.py',\n",
      " 'MOBILE_SAM_CHECKPOINT_PATH': './saves/mobile_sam.pt',\n",
      " 'SAM_CHECKPOINT_PATH': './saves/sam_vit_h_4b8939.pth',\n",
      " 'SAM_ENCODER_VERSION': 'vit_h',\n",
      " 'SAM_NUM_POINTS_PER_BATCH': 64,\n",
      " 'SAM_NUM_POINTS_PER_SIDE': 32,\n",
      " 'SAM_OVERLAP_THRESHOLD': 0.8,\n",
      " 'SAM_PRED_IOU_THRESHOLD': 0.88,\n",
      " 'amp': False,\n",
      " 'chunk_size': -1,\n",
      " 'detection_every': 5,\n",
      " 'disable_long_term': False,\n",
      " 'do_not_pluralize': False,\n",
      " 'enable_long_term': True,\n",
      " 'engulf_threshold': 0.2,\n",
      " 'img_path': './example/vipseg',\n",
      " 'key_dim': 64,\n",
      " 'match_and_merge_mode': 'iou',\n",
      " 'max_long_term_elements': 10000,\n",
      " 'max_mid_term_frames': 10,\n",
      " 'max_missed_detection_count': 10,\n",
      " 'max_num_objects': -1,\n",
      " 'mem_every': 5,\n",
      " 'min_mid_term_frames': 5,\n",
      " 'model': './saves/DEVA-propagation.pth',\n",
      " 'num_prototypes': 128,\n",
      " 'num_voting_frames': 3,\n",
      " 'output': None,\n",
      " 'pix_feat_dim': 512,\n",
      " 'prompt': None,\n",
      " 'sam_variant': 'original',\n",
      " 'save_all': False,\n",
      " 'size': 480,\n",
      " 'temporal_setting': 'semionline',\n",
      " 'top_k': 30,\n",
      " 'value_dim': 512}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/wangz3/miniconda3/envs/ecole-video/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final text_encoder_type: bert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import path\n",
    "from argparse import ArgumentParser\n",
    "import pprint\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from deva.model.network import DEVA\n",
    "from deva.inference.inference_core import DEVAInferenceCore\n",
    "from deva.inference.result_utils import ResultSaver\n",
    "from deva.inference.eval_args import add_common_eval_args, get_model_and_config\n",
    "from deva.inference.demo_utils import flush_buffer\n",
    "from deva.ext.ext_eval_args import add_ext_eval_args, add_text_default_args\n",
    "from deva.ext.grounding_dino import get_grounding_dino_model\n",
    "from deva.ext.with_text_processor import process_frame_with_text as process_frame\n",
    "\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "torch.autograd.set_grad_enabled(False)\n",
    "\n",
    "# for id2rgb\n",
    "np.random.seed(42)\n",
    "\n",
    "# default parameters\n",
    "parser = ArgumentParser()\n",
    "add_common_eval_args(parser)\n",
    "add_ext_eval_args(parser)\n",
    "add_text_default_args(parser)\n",
    "\n",
    "# load model and config\n",
    "args = parser.parse_args([])\n",
    "cfg = vars(args)\n",
    "cfg['enable_long_term'] = True\n",
    "\n",
    "print('cfg:')\n",
    "pprint.pprint(cfg)\n",
    "\n",
    "# Load our checkpoint\n",
    "# device = torch.device('cuda') if cuda_available else torch.device('cpu')\n",
    "# deva_model = DEVA(cfg).to(device).eval()\n",
    "deva_model = DEVA(cfg).cuda().eval()\n",
    "if args.model is not None:\n",
    "    model_weights = torch.load(args.model)\n",
    "    deva_model.load_weights(model_weights)\n",
    "else:\n",
    "    print('No model loaded.')\n",
    "\n",
    "gd_model, sam_model = get_grounding_dino_model(cfg, 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set hyperparameters\n",
    "cfg['enable_long_term_count_usage'] = True\n",
    "cfg['max_num_objects'] = 50\n",
    "cfg['size'] = 480\n",
    "cfg['DINO_THRESHOLD'] = 0.35\n",
    "cfg['amp'] = True\n",
    "cfg['chunk_size'] = 4\n",
    "cfg['detection_every'] = 5\n",
    "cfg['max_missed_detection_count'] = 10\n",
    "cfg['sam_variant'] = 'original'\n",
    "cfg['temporal_setting'] = 'online' # semionline usually works better; but online is faster for this demo\n",
    "cfg['pluralize'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "General configuration for OpenCV 4.8.0 =====================================\n",
      "  Version control:               4.8.0-dirty\n",
      "\n",
      "  Platform:\n",
      "    Timestamp:                   2023-08-09T11:41:23Z\n",
      "    Host:                        Linux 5.15.0-1042-azure x86_64\n",
      "    CMake:                       3.27.1\n",
      "    CMake generator:             Unix Makefiles\n",
      "    CMake build tool:            /bin/gmake\n",
      "    Configuration:               Release\n",
      "\n",
      "  CPU/HW features:\n",
      "    Baseline:                    SSE SSE2 SSE3\n",
      "      requested:                 SSE3\n",
      "    Dispatched code generation:  SSE4_1 SSE4_2 FP16 AVX AVX2 AVX512_SKX\n",
      "      requested:                 SSE4_1 SSE4_2 AVX FP16 AVX2 AVX512_SKX\n",
      "      SSE4_1 (16 files):         + SSSE3 SSE4_1\n",
      "      SSE4_2 (1 files):          + SSSE3 SSE4_1 POPCNT SSE4_2\n",
      "      FP16 (0 files):            + SSSE3 SSE4_1 POPCNT SSE4_2 FP16 AVX\n",
      "      AVX (7 files):             + SSSE3 SSE4_1 POPCNT SSE4_2 AVX\n",
      "      AVX2 (35 files):           + SSSE3 SSE4_1 POPCNT SSE4_2 FP16 FMA3 AVX AVX2\n",
      "      AVX512_SKX (5 files):      + SSSE3 SSE4_1 POPCNT SSE4_2 FP16 FMA3 AVX AVX2 AVX_512F AVX512_COMMON AVX512_SKX\n",
      "\n",
      "  C/C++:\n",
      "    Built as dynamic libs?:      NO\n",
      "    C++ standard:                11\n",
      "    C++ Compiler:                /opt/rh/devtoolset-10/root/usr/bin/c++  (ver 10.2.1)\n",
      "    C++ flags (Release):         -Wl,-strip-all   -fsigned-char -W -Wall -Wreturn-type -Wnon-virtual-dtor -Waddress -Wsequence-point -Wformat -Wformat-security -Wmissing-declarations -Wundef -Winit-self -Wpointer-arith -Wshadow -Wsign-promo -Wuninitialized -Wsuggest-override -Wno-delete-non-virtual-dtor -Wno-comment -Wimplicit-fallthrough=3 -Wno-strict-overflow -fdiagnostics-show-option -Wno-long-long -pthread -fomit-frame-pointer -ffunction-sections -fdata-sections  -msse -msse2 -msse3 -fvisibility=hidden -fvisibility-inlines-hidden -O3 -DNDEBUG  -DNDEBUG\n",
      "    C++ flags (Debug):           -Wl,-strip-all   -fsigned-char -W -Wall -Wreturn-type -Wnon-virtual-dtor -Waddress -Wsequence-point -Wformat -Wformat-security -Wmissing-declarations -Wundef -Winit-self -Wpointer-arith -Wshadow -Wsign-promo -Wuninitialized -Wsuggest-override -Wno-delete-non-virtual-dtor -Wno-comment -Wimplicit-fallthrough=3 -Wno-strict-overflow -fdiagnostics-show-option -Wno-long-long -pthread -fomit-frame-pointer -ffunction-sections -fdata-sections  -msse -msse2 -msse3 -fvisibility=hidden -fvisibility-inlines-hidden -g  -O0 -DDEBUG -D_DEBUG\n",
      "    C Compiler:                  /opt/rh/devtoolset-10/root/usr/bin/cc\n",
      "    C flags (Release):           -Wl,-strip-all   -fsigned-char -W -Wall -Wreturn-type -Waddress -Wsequence-point -Wformat -Wformat-security -Wmissing-declarations -Wmissing-prototypes -Wstrict-prototypes -Wundef -Winit-self -Wpointer-arith -Wshadow -Wuninitialized -Wno-comment -Wimplicit-fallthrough=3 -Wno-strict-overflow -fdiagnostics-show-option -Wno-long-long -pthread -fomit-frame-pointer -ffunction-sections -fdata-sections  -msse -msse2 -msse3 -fvisibility=hidden -O3 -DNDEBUG  -DNDEBUG\n",
      "    C flags (Debug):             -Wl,-strip-all   -fsigned-char -W -Wall -Wreturn-type -Waddress -Wsequence-point -Wformat -Wformat-security -Wmissing-declarations -Wmissing-prototypes -Wstrict-prototypes -Wundef -Winit-self -Wpointer-arith -Wshadow -Wuninitialized -Wno-comment -Wimplicit-fallthrough=3 -Wno-strict-overflow -fdiagnostics-show-option -Wno-long-long -pthread -fomit-frame-pointer -ffunction-sections -fdata-sections  -msse -msse2 -msse3 -fvisibility=hidden -g  -O0 -DDEBUG -D_DEBUG\n",
      "    Linker flags (Release):      -Wl,--exclude-libs,libippicv.a -Wl,--exclude-libs,libippiw.a -L/ffmpeg_build/lib  -Wl,--gc-sections -Wl,--as-needed -Wl,--no-undefined  \n",
      "    Linker flags (Debug):        -Wl,--exclude-libs,libippicv.a -Wl,--exclude-libs,libippiw.a -L/ffmpeg_build/lib  -Wl,--gc-sections -Wl,--as-needed -Wl,--no-undefined  \n",
      "    ccache:                      YES\n",
      "    Precompiled headers:         NO\n",
      "    Extra dependencies:          /lib64/libopenblas.so Qt5::Core Qt5::Gui Qt5::Widgets Qt5::Test Qt5::Concurrent /usr/local/lib/libpng.so /lib64/libz.so dl m pthread rt\n",
      "    3rdparty dependencies:       libprotobuf ade ittnotify libjpeg-turbo libwebp libtiff libopenjp2 IlmImf quirc ippiw ippicv\n",
      "\n",
      "  OpenCV modules:\n",
      "    To be built:                 calib3d core dnn features2d flann gapi highgui imgcodecs imgproc ml objdetect photo python3 stitching video videoio\n",
      "    Disabled:                    world\n",
      "    Disabled by dependency:      -\n",
      "    Unavailable:                 java python2 ts\n",
      "    Applications:                -\n",
      "    Documentation:               NO\n",
      "    Non-free algorithms:         NO\n",
      "\n",
      "  GUI:                           QT5\n",
      "    QT:                          YES (ver 5.15.0 )\n",
      "      QT OpenGL support:         NO\n",
      "    GTK+:                        NO\n",
      "    VTK support:                 NO\n",
      "\n",
      "  Media I/O: \n",
      "    ZLib:                        /lib64/libz.so (ver 1.2.7)\n",
      "    JPEG:                        libjpeg-turbo (ver 2.1.3-62)\n",
      "    WEBP:                        build (ver encoder: 0x020f)\n",
      "    PNG:                         /usr/local/lib/libpng.so (ver 1.6.40)\n",
      "    TIFF:                        build (ver 42 - 4.2.0)\n",
      "    JPEG 2000:                   build (ver 2.5.0)\n",
      "    OpenEXR:                     build (ver 2.3.0)\n",
      "    HDR:                         YES\n",
      "    SUNRASTER:                   YES\n",
      "    PXM:                         YES\n",
      "    PFM:                         YES\n",
      "\n",
      "  Video I/O:\n",
      "    DC1394:                      NO\n",
      "    FFMPEG:                      YES\n",
      "      avcodec:                   YES (59.37.100)\n",
      "      avformat:                  YES (59.27.100)\n",
      "      avutil:                    YES (57.28.100)\n",
      "      swscale:                   YES (6.7.100)\n",
      "      avresample:                NO\n",
      "    GStreamer:                   NO\n",
      "    v4l/v4l2:                    YES (linux/videodev2.h)\n",
      "\n",
      "  Parallel framework:            pthreads\n",
      "\n",
      "  Trace:                         YES (with Intel ITT)\n",
      "\n",
      "  Other third-party libraries:\n",
      "    Intel IPP:                   2021.8 [2021.8.0]\n",
      "           at:                   /io/_skbuild/linux-x86_64-3.7/cmake-build/3rdparty/ippicv/ippicv_lnx/icv\n",
      "    Intel IPP IW:                sources (2021.8.0)\n",
      "              at:                /io/_skbuild/linux-x86_64-3.7/cmake-build/3rdparty/ippicv/ippicv_lnx/iw\n",
      "    VA:                          NO\n",
      "    Lapack:                      YES (/lib64/libopenblas.so)\n",
      "    Eigen:                       NO\n",
      "    Custom HAL:                  NO\n",
      "    Protobuf:                    build (3.19.1)\n",
      "    Flatbuffers:                 builtin/3rdparty (23.5.9)\n",
      "\n",
      "  OpenCL:                        YES (no extra features)\n",
      "    Include path:                /io/opencv/3rdparty/include/opencl/1.2\n",
      "    Link libraries:              Dynamic load\n",
      "\n",
      "  Python 3:\n",
      "    Interpreter:                 /opt/python/cp37-cp37m/bin/python3.7 (ver 3.7.17)\n",
      "    Libraries:                   libpython3.7m.a (ver 3.7.17)\n",
      "    numpy:                       /home/ci/.local/lib/python3.7/site-packages/numpy/core/include (ver 1.17.0)\n",
      "    install path:                python/cv2/python-3\n",
      "\n",
      "  Python (for build):            /opt/python/cp37-cp37m/bin/python3.7\n",
      "\n",
      "  Java:                          \n",
      "    ant:                         NO\n",
      "    Java:                        NO\n",
      "    JNI:                         NO\n",
      "    Java wrappers:               NO\n",
      "    Java tests:                  NO\n",
      "\n",
      "  Install to:                    /io/_skbuild/linux-x86_64-3.7/cmake-install\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "print(cv2.getBuildInformation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/299 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x30387076/'vp80' is not supported with codec id 139 and format 'webm / WebM'\n",
      "/data/wangz3/miniconda3/envs/ecole-video/lib/python3.9/site-packages/transformers/modeling_utils.py:909: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/data/wangz3/miniconda3/envs/ecole-video/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      " 64%|██████▎   | 190/299 [01:29<00:34,  3.11it/s]/data/wangz3/projects/ecole-video-action/third_party/Tracking-Anything-with-DEVA/deva/inference/inference_core.py:71: RuntimeWarning: Empty object mask!\n",
      "  warnings.warn('Empty object mask!', RuntimeWarning)\n",
      " 64%|██████▍   | 191/299 [01:30<00:52,  2.07it/s]/data/wangz3/projects/ecole-video-action/third_party/Tracking-Anything-with-DEVA/deva/inference/inference_core.py:97: RuntimeWarning: Trying to segment without any memory!\n",
      "  warnings.warn('Trying to segment without any memory!', RuntimeWarning)\n",
      "100%|██████████| 299/299 [02:11<00:00,  2.27it/s]\n"
     ]
    }
   ],
   "source": [
    "## specify input and output\n",
    "\n",
    "# SOURCE_VIDEO_PATH = f\"./data/example.mp4\"\n",
    "# # OUTPUT_VIDEO_PATH = f\"./data/example_output.webm\"\n",
    "# # OUTPUT_VIDEO_PATH = f\"./data/example_output.mp4\"\n",
    "# prompt = \"person.hat.horse\"\n",
    "\n",
    "# SOURCE_VIDEO_PATH = f\"./data/video7434.mp4\"\n",
    "# OUTPUT_VIDEO_PATH = f\"./data/video7434_output.webm\"\n",
    "# prompt = \"person.food\"\n",
    "\n",
    "SOURCE_VIDEO_PATH = f\"./data/video7436.mp4\"\n",
    "OUTPUT_VIDEO_PATH = f\"./data/video7436_output.webm\"\n",
    "prompt = \"person holding a gun. woman sitting\"\n",
    "\n",
    "cfg['DINO_THRESHOLD'] = 0.5\n",
    "\n",
    "# run DEVA\n",
    "from deva.ext.with_text_processor import process_frame_with_text as process_frame_text\n",
    "import tempfile\n",
    "import cv2\n",
    "\n",
    "cfg['prompt'] = prompt\n",
    "\n",
    "deva = DEVAInferenceCore(deva_model, config=cfg)\n",
    "deva.next_voting_frame = cfg['num_voting_frames'] - 1\n",
    "deva.enabled_long_id()\n",
    "\n",
    "# obtain temporary directory\n",
    "result_saver = ResultSaver(None, None, dataset='gradio', object_manager=deva.object_manager)\n",
    "writer_initizied = False\n",
    "\n",
    "cap = cv2.VideoCapture(SOURCE_VIDEO_PATH)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "ti = 0\n",
    "# only an estimate\n",
    "with torch.cuda.amp.autocast(enabled=cfg['amp']):\n",
    "    with tqdm(total=int(cap.get(cv2.CAP_PROP_FRAME_COUNT))) as pbar:\n",
    "        while (cap.isOpened()):\n",
    "            ret, frame = cap.read()\n",
    "            if ret == True:\n",
    "                if not writer_initizied:\n",
    "                    h, w = frame.shape[:2]\n",
    "                    if OUTPUT_VIDEO_PATH.endswith('.webm'):\n",
    "                        writer = cv2.VideoWriter(OUTPUT_VIDEO_PATH, cv2.VideoWriter_fourcc(*'vp80'), fps, (w, h)) # webm\n",
    "                    else:\n",
    "                        writer = cv2.VideoWriter(OUTPUT_VIDEO_PATH, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h)) # mp4?\n",
    "                    writer_initizied = True\n",
    "                    result_saver.writer = writer\n",
    "\n",
    "                process_frame_text(deva,\n",
    "                                    gd_model,\n",
    "                                    sam_model,\n",
    "                                    'null.png',\n",
    "                                    result_saver,\n",
    "                                    ti,\n",
    "                                    image_np=frame)\n",
    "                ti += 1\n",
    "                pbar.update(1)\n",
    "            else:\n",
    "                break\n",
    "    flush_buffer(deva, result_saver)\n",
    "writer.release()\n",
    "cap.release()\n",
    "deva.clear_buffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"./data/video7434_output.webm\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "video_path = OUTPUT_VIDEO_PATH\n",
    "# video_path = \"/data/wangz3/projects/ecole-video-action/third_party/Tracking-Anything-with-DEVA/data/example.mp4\"\n",
    "video = Video(video_path)\n",
    "video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecole-video",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
